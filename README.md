# ğŸ Snake AI - Evolutionary Reinforcement Learning

> Um sistema completo de IA que aprende a jogar Snake do zero, utilizando **Redes Neurais (MLP)** construÃ­das manualmente com NumPy e otimizadas via **Algoritmos GenÃ©ticos**.

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![NumPy](https://img.shields.io/badge/Library-NumPy-orange)
![Pygame](https://img.shields.io/badge/Visuals-Pygame-green)
![Status](https://img.shields.io/badge/Status-Active-brightgreen)

## ğŸ“‹ Sobre o Projeto

Este projeto Ã© uma implementaÃ§Ã£o educacional e tÃ©cnica de Aprendizado por ReforÃ§o Evolutivo. O diferencial Ã© que **nÃ£o utilizamos frameworks de Deep Learning** (como PyTorch, TensorFlow ou Keras). Toda a matemÃ¡tica da Rede Neural (Feedforward, FunÃ§Ãµes de AtivaÃ§Ã£o, ManipulaÃ§Ã£o de Pesos) foi implementada utilizando apenas Ã¡lgebra linear com **NumPy**.

O agente "enxerga" o ambiente, processa as informaÃ§Ãµes em sua rede neural e decide a prÃ³xima aÃ§Ã£o. AtravÃ©s da seleÃ§Ã£o natural, as cobras que jogam melhor sobrevivem e passam seus "genes" (pesos da rede) para as prÃ³ximas geraÃ§Ãµes.

---

## âœ¨ Funcionalidades e Diferenciais

### ğŸ§  IA "From Scratch"
- **MLP Personalizada:** Rede Neural Feedforward implementada com multiplicaÃ§Ã£o de matrizes.
- **Arquitetura FlexÃ­vel:** Camadas ocultas configurÃ¡veis (PadrÃ£o: `8 -> 16 -> 12 -> 3`).
- **AtivaÃ§Ãµes:** `ReLU` nas camadas ocultas e `Tanh` na saÃ­da para decisÃ£o de direÃ§Ã£o.

### ğŸ§¬ Algoritmo GenÃ©tico Robusto
- **EvoluÃ§Ã£o ContÃ­nua:** SeleÃ§Ã£o por torneio e elitismo (preserva os top 5%).
- **Diversidade GenÃ©tica:** Operadores de Crossover e MutaÃ§Ã£o Gaussiana ajustÃ¡vel.
- **HeurÃ­stica de Fitness DinÃ¢mica:** O critÃ©rio de sucesso muda conforme a cobra cresce:
  - *Fase Jovem:* Foco agressivo em comer maÃ§Ã£s.
  - *Fase Adulta:* Foco em sobrevivÃªncia, evitar becos sem saÃ­da e maximizar tempo de vida.

### ğŸ‘€ Sensores AvanÃ§ados (Input)
A cobra nÃ£o vÃª a tela como nÃ³s (pixels). Ela percebe o mundo atravÃ©s de 8 sensores normalizados:
1.  **Perigo Imediato (3):** Paredes ou corpo Ã  Frente, Esquerda e Direita.
2.  **DireÃ§Ã£o da Comida (1):** Ã‚ngulo relativo entre a cabeÃ§a e a maÃ§Ã£.
3.  **Tamanho (1):** Comprimento atual normalizado.
4.  **Instinto de SobrevivÃªncia (3):** Utiliza o algoritmo de **Dijkstra** para calcular se existe um caminho livre atÃ© a prÃ³pria cauda em cada direÃ§Ã£o possÃ­vel. Isso evita que a IA entre em "becos sem saÃ­da" (espaÃ§os fechados de onde nÃ£o conseguirÃ¡ sair).

### ğŸ“Š Dashboard e VisualizaÃ§Ã£o
- **Painel em Tempo Real:** Acompanhe 9 jogos simultÃ¢neos enquanto a IA treina.
- **GrÃ¡ficos:** Plotagem ao vivo da curva de aprendizado (Fitness MÃ©dio x Melhor Fitness).
- **Snapshots:** O sistema salva automaticamente o "cÃ©rebro" (modelo .npy) das melhores cobras.

---

## ğŸ“ˆ Resultados Recentes

O sistema demonstra convergÃªncia consistente. Em treinamentos recentes, observamos:
- **GeraÃ§Ã£o 0:** Movimentos aleatÃ³rios, colisÃ£o imediata.
- **GeraÃ§Ã£o 50:** JÃ¡ aprende a buscar comida e evitar paredes simples.
- **GeraÃ§Ã£o 150+:** Domina a estratÃ©gia de sobrevivÃªncia, circulando o mapa quando encurralada e planejando rotas.

*Exemplo de Log de Treinamento (Gen 149):*
- **Melhor Fitness:** ~14.99
- **MÃ©dia da PopulaÃ§Ã£o:** ~4.48 (Crescimento constante)

---

## ğŸš€ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- Pip

### 1. Instalar DependÃªncias
```bash
pip install -r requirements.txt
```
*As libs principais sÃ£o apenas `numpy`, `pygame`, `matplotlib` e `tqdm`.*

### 2. Treinar a IA
Para iniciar um novo experimento evolutivo:
```bash
python main_train.py
```
*Uma janela de configuraÃ§Ã£o abrirÃ¡ permitindo ajustar o tamanho do grid, populaÃ§Ã£o, velocidade, etc.*

### 3. Assistir ao Melhor Agente
Para ver o resultado final de um treinamento (substitua o arquivo pelo seu modelo gerado):
```bash
python play_best.py --model models/best_overall.npy
```

---

## ğŸ“‚ Estrutura do CÃ³digo

```
Snake/
â”œâ”€â”€ main_train.py           # Orquestrador do treinamento
â”œâ”€â”€ snake_ai/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ neural_net.py   # O "cÃ©rebro" (MatemÃ¡tica da MLP)
â”‚   â”‚   â””â”€â”€ genetic_algorithm.py # O "motor" da evoluÃ§Ã£o
â”‚   â”œâ”€â”€ env/
â”‚   â”‚   â”œâ”€â”€ snake_env.py    # Regras do jogo
â”‚   â”‚   â””â”€â”€ state_encoding.py # Sensores (Dijkstra, VisÃ£o)
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ evaluation.py   # FunÃ§Ã£o de Fitness DinÃ¢mica
â”‚   â””â”€â”€ visualization/      # Dashboard Pygame e Plots
â””â”€â”€ models/                 # Onde os .npy salvos ficam
```

---

## ğŸ› ï¸ Tecnologias
- **Linguagem:** Python
- **Core Logic:** NumPy
- **Game Engine:** Pygame
- **Data Viz:** Matplotlib

---

## ğŸ“ LicenÃ§a
Este projeto foi desenvolvido para fins de estudo em InteligÃªncia Artificial e Engenharia de Software. Sinta-se livre para usar, modificar e compartilhar!
