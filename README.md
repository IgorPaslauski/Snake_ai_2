# Snake AI Training System

Sistema completo para treinar uma Intelig√™ncia Artificial para jogar Snake (Jogo da Cobrinha) usando **Redes Neurais Artificiais (MLP)** e **Algoritmos Gen√©ticos (GA)**. O c√≥digo foi desenvolvido em Python puro com NumPy, sem frameworks de Deep Learning (como PyTorch ou TensorFlow).

## üìã √çndice

- [Vis√£o Geral](#vis√£o-geral)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Instala√ß√£o](#instala√ß√£o)
- [Como Usar](#como-usar)
- [Arquitetura e Funcionamento](#arquitetura-e-funcionamento)
- [Configura√ß√µes e Par√¢metros](#configura√ß√µes-e-par√¢metros)
- [Arquivos e M√≥dulos](#arquivos-e-m√≥dulos)

---

## üéØ Vis√£o Geral

Este projeto implementa um sistema de aprendizado por refor√ßo evolutivo onde:

1. **Agentes** (cobras controladas por IA) jogam Snake em um ambiente simulado
2. Cada agente possui uma **Rede Neural (MLP)** que decide as a√ß√µes baseadas no estado do jogo
3. Um **Algoritmo Gen√©tico** evolui os pesos das redes neurais atrav√©s de gera√ß√µes
4. Os melhores agentes s√£o selecionados, cruzados e mutados para criar a pr√≥xima gera√ß√£o
5. O processo se repete at√© que os agentes aprendam a jogar eficientemente

### Caracter√≠sticas Principais

- ‚úÖ **Implementa√ß√£o do zero**: Sem depend√™ncias de frameworks de ML
- ‚úÖ **Visualiza√ß√£o em tempo real**: Dashboard interativo com 9 jogos simult√¢neos
- ‚úÖ **Heur√≠stica din√¢mica**: Sistema de recompensas que se adapta conforme a cobra cresce
- ‚úÖ **Interface gr√°fica**: Tela de configura√ß√£o para ajustar hiperpar√¢metros facilmente
- ‚úÖ **Logging completo**: Estat√≠sticas salvas em CSV e gr√°ficos de evolu√ß√£o

---

## üìÅ Estrutura do Projeto

```
Snake/
‚îú‚îÄ‚îÄ snake_ai/                    # Pacote principal
‚îÇ   ‚îú‚îÄ‚îÄ agents/                  # Agentes e algoritmos gen√©ticos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ neural_net.py       # Implementa√ß√£o da MLP
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ genome.py           # Fun√ß√µes de manipula√ß√£o de genomas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ genetic_algorithm.py # Algoritmo gen√©tico
‚îÇ   ‚îú‚îÄ‚îÄ env/                    # Ambiente do jogo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ snake_env.py        # L√≥gica do jogo Snake
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ state_encoding.py   # Codifica√ß√£o do estado para a rede
‚îÇ   ‚îú‚îÄ‚îÄ training/               # L√≥gica de treinamento
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluation.py       # Fun√ß√£o de fitness e avalia√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ utils/                  # Utilit√°rios
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ launcher.py         # Tela de configura√ß√£o (Tkinter)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger.py           # Logger CSV
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ paths.py            # Defini√ß√£o de diret√≥rios
‚îÇ   ‚îî‚îÄ‚îÄ visualization/         # Visualiza√ß√£o
‚îÇ       ‚îú‚îÄ‚îÄ dashboard.py        # Dashboard unificado (Pygame)
‚îÇ       ‚îú‚îÄ‚îÄ plots.py            # Gr√°ficos est√°ticos e din√¢micos
‚îÇ       ‚îú‚îÄ‚îÄ board_snapshots.py  # Snapshots do tabuleiro
‚îÇ       ‚îî‚îÄ‚îÄ live_view.py        # Visualizador simples (legado)
‚îú‚îÄ‚îÄ main_train.py               # Script principal de treinamento
‚îú‚îÄ‚îÄ play_best.py                # Script para assistir melhor agente
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias Python
‚îî‚îÄ‚îÄ README.md                   # Este arquivo
```

**Diret√≥rios gerados durante o treinamento:**
- `models/` - Genomas salvos (melhor de cada gera√ß√£o + melhor global)
- `logs/` - Arquivos CSV com estat√≠sticas de treinamento
- `plots/` - Gr√°ficos de evolu√ß√£o do fitness
- `snapshots/` - Imagens est√°ticas do tabuleiro em gera√ß√µes espec√≠ficas

---

## üöÄ Instala√ß√£o

### Pr√©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### Passos

1. **Clone o reposit√≥rio** (ou baixe os arquivos):
   ```bash
   git clone <url-do-repositorio>
   cd Snake
   ```

2. **Instale as depend√™ncias**:
   ```bash
   pip install -r requirements.txt
   ```

   As depend√™ncias incluem:
   - `numpy` - Opera√ß√µes matem√°ticas e arrays
   - `matplotlib` - Gr√°ficos e visualiza√ß√µes
   - `pygame` - Renderiza√ß√£o gr√°fica e dashboard
   - `tqdm` - Barras de progresso no terminal

---

## üéÆ Como Usar

### 1. Treinamento

Para iniciar o treinamento, execute:

```bash
python main_train.py
```

**O que acontece:**

1. **Tela de Configura√ß√£o**: Uma janela Tkinter ser√° aberta onde voc√™ pode configurar:
   - N√∫mero de gera√ß√µes
   - Tamanho da popula√ß√£o
   - Dimens√µes do tabuleiro (largura x altura)
   - Energia inicial (atualiza automaticamente baseado no tamanho do grid)
   - Taxa de muta√ß√£o
   - Se a cobra cresce ao comer
   - Se deseja visualizar o dashboard ao vivo
   - Velocidade de visualiza√ß√£o (FPS)

2. **Inicializa√ß√£o**: O sistema cria os diret√≥rios necess√°rios (`models/`, `logs/`, `plots/`, `snapshots/`)

3. **Loop de Treinamento**: Para cada gera√ß√£o:
   - Avalia todos os agentes da popula√ß√£o
   - Calcula fitness (baseado em ma√ß√£s comidas e sobreviv√™ncia)
   - Salva o melhor genoma da gera√ß√£o e o melhor global
   - Atualiza logs CSV
   - Renderiza dashboard (se habilitado) mostrando os top 9 agentes
   - Gera snapshots est√°ticos a cada 50 gera√ß√µes
   - Evolui a popula√ß√£o (sele√ß√£o, crossover, muta√ß√£o)

4. **Finaliza√ß√£o**: Ao terminar (ou ao fechar o dashboard), gera um gr√°fico final de evolu√ß√£o do fitness

**Interrup√ß√£o:**
- Pressione `Ctrl+C` no terminal para interromper o treinamento
- Feche a janela do dashboard para parar o treinamento graciosamente

### 2. Visualiza√ß√£o do Melhor Agente

Para assistir o melhor agente treinado jogando:

```bash
python play_best.py
```

**Op√ß√µes:**
- `--model`: Caminho para o arquivo de modelo (padr√£o: `models/best_overall.npy`)
- `--speed`: Velocidade do jogo em FPS (padr√£o: 10)

**Exemplo:**
```bash
python play_best.py --model models/best_gen_0100.npy --speed 15
```

---

## üß† Arquitetura e Funcionamento

### 1. Ambiente do Jogo (`SnakeEnv`)

O ambiente simula o jogo Snake em um grid 2D:

- **Estado**: Posi√ß√µes da cobra (cabe√ßa + corpo), posi√ß√£o da ma√ß√£, dire√ß√£o atual, energia restante
- **A√ß√µes**: 0 (virar esquerda), 1 (seguir reto), 2 (virar direita)
- **Regras**:
  - A cobra se move 1 c√©lula por passo
  - Cresce ao comer uma ma√ß√£ (se `grow_on_eat=True`)
  - Morre ao colidir com parede ou com seu pr√≥prio corpo
  - Sistema de energia: come√ßa com `width * height`, reseta ao comer, morre se chegar a 0
- **Recompensas**:
  - +10 por comer ma√ß√£
  - -1 por morrer
  - 0 para passos neutros

### 2. Codifica√ß√£o de Estado (`encode_state`)

O estado do jogo √© convertido em um vetor num√©rico de **6 entradas**:

1. **Perigo (3 valores)**: Flags bin√°rias indicando colis√£o iminente √† frente, direita e esquerda
2. **Ma√ß√£ (2 valores)**:
   - √Çngulo relativo √† dire√ß√£o atual da cabe√ßa (normalizado entre -1 e 1)
   - Dist√¢ncia normalizada (0 a 1)
3. **Tamanho (1 valor)**: Comprimento atual da cobra normalizado pelo tamanho m√°ximo do grid

### 3. Rede Neural (`NeuralNetwork`)

**Arquitetura MLP:**
- **Entrada**: 6 neur√¥nios (estado codificado)
- **Camadas Ocultas**: [16, 12] neur√¥nios com ativa√ß√£o **ReLU**
- **Sa√≠da**: 3 neur√¥nios (scores para cada a√ß√£o) com ativa√ß√£o **Tanh**
- **Decis√£o**: A√ß√£o com maior score (`argmax`)

**M√©todos principais:**
- `forward(state)`: Propaga√ß√£o para frente, retorna scores das a√ß√µes
- `forward_debug(state)`: Vers√£o que retorna ativa√ß√µes de todas as camadas (para visualiza√ß√£o)
- `get_weights_flat()`: Retorna todos os pesos e biases como vetor 1D (genoma)
- `set_weights_flat(genome)`: Define pesos e biases a partir de um genoma

### 4. Algoritmo Gen√©tico (`GeneticAlgorithm`)

**Ciclo evolutivo:**

1. **Inicializa√ß√£o**: Popula√ß√£o de genomas aleat√≥rios (pesos da rede)
2. **Avalia√ß√£o**: Cada genoma √© testado no jogo e recebe um fitness
3. **Sele√ß√£o**: Os melhores s√£o selecionados (elitismo + torneio)
4. **Crossover**: Genomas s√£o cruzados (uniforme ou single-point)
5. **Muta√ß√£o**: Pesos s√£o modificados com ru√≠do gaussiano
6. **Nova Gera√ß√£o**: Processo se repete

**Hiperpar√¢metros:**
- **Elitismo**: 5% da popula√ß√£o (melhores s√£o preservados)
- **Taxa de Muta√ß√£o**: Configur√°vel (padr√£o: 0.1)
- **Desvio Padr√£o da Muta√ß√£o**: 0.2
- **Tipo de Crossover**: Uniforme (cada peso vem de um dos pais aleatoriamente)

### 5. Fun√ß√£o de Fitness (`evaluate_genome`)

**Heur√≠stica Din√¢mica:**

A fun√ß√£o de fitness se adapta conforme a cobra cresce:

- **Fase 1 (Cobra Pequena)**: Foco em comer
  - Recompensa alta por ma√ß√£s (100 pontos por ma√ß√£)
  - Recompensa baixa por passos (0.1 por passo)
  - Penalidade forte se morrer sem comer nada (-50)

- **Fase 2 (Cobra Grande)**: Foco em sobreviv√™ncia
  - Recompensa alta por ma√ß√£s (200 pontos por ma√ß√£)
  - Recompensa alta por passos (2.0 por passo)
  - Penalidade severa por colis√£o com o corpo (-500)
  - Penalidade por colis√£o com parede (-100)
  - B√¥nus cont√≠nuo se a cauda for alcan√ß√°vel (+0.5 por passo)
  - Penalidade se a cauda n√£o for alcan√ß√°vel (-0.5 por passo)

**Avalia√ß√£o:**
- Cada genoma √© testado em 3 epis√≥dios
- Fitness final = m√©dia dos fitness dos epis√≥dios

---

## ‚öôÔ∏è Configura√ß√µes e Par√¢metros

### Configura√ß√µes do Ambiente

Definidas na tela de configura√ß√£o ou em `main_train.py`:

```python
ENV_CONFIG = {
    "width": 10,              # Largura do tabuleiro
    "height": 10,             # Altura do tabuleiro
    "initial_energy": 100,    # Energia inicial (padr√£o: width * height)
    "grow_on_eat": True       # Se a cobra cresce ao comer
}
```

### Configura√ß√µes do Algoritmo Gen√©tico

```python
POPULATION_SIZE = 150        # Tamanho da popula√ß√£o
GENERATIONS = 1000           # N√∫mero de gera√ß√µes
MUTATION_RATE = 0.1         # Taxa de muta√ß√£o (0-1)
MUTATION_STD = 0.2           # Desvio padr√£o do ru√≠do gaussiano
ELITISM = 5% da popula√ß√£o    # Quantos melhores preservar
```

### Configura√ß√µes da Rede Neural

```python
LAYER_SIZES = [6, 16, 12, 3]  # [Input, Hidden1, Hidden2, Output]
```

### Configura√ß√µes de Treinamento

```python
EPISODES_PER_EVAL = 3        # Epis√≥dios por avalia√ß√£o de genoma
SNAPSHOT_INTERVAL = 50       # Intervalo para salvar snapshots
```

---

## üìÑ Arquivos e M√≥dulos

### Scripts Principais

#### `main_train.py`
Script principal que orquestra todo o processo de treinamento:
- Abre tela de configura√ß√£o
- Inicializa ambiente, rede neural e algoritmo gen√©tico
- Loop principal: avalia√ß√£o ‚Üí evolu√ß√£o ‚Üí logging ‚Üí visualiza√ß√£o
- Salva modelos e gera gr√°ficos finais

#### `play_best.py`
Script para visualizar o melhor agente jogando:
- Carrega genoma salvo
- Cria ambiente e rede neural
- Renderiza jogo em tempo real com Pygame

### M√≥dulos do Pacote `snake_ai`

#### `env/snake_env.py`
**Classe `SnakeEnv`**: Implementa o ambiente do jogo
- `reset()`: Reinicia o jogo para estado inicial
- `step(action)`: Executa uma a√ß√£o e retorna (estado, recompensa, done, info)
- `_get_state_info()`: Retorna dicion√°rio com informa√ß√µes do estado atual
- `is_tail_reachable()`: Verifica se a cabe√ßa pode alcan√ßar a cauda (BFS)

#### `env/state_encoding.py`
**Fun√ß√£o `encode_state(env)`**: Converte estado do jogo em vetor num√©rico
- Calcula perigos (colis√µes iminentes)
- Calcula posi√ß√£o relativa da ma√ß√£ (√¢ngulo e dist√¢ncia)
- Normaliza valores para o intervalo adequado

#### `agents/neural_net.py`
**Classe `NeuralNetwork`**: Implementa√ß√£o manual de MLP
- Inicializa√ß√£o de pesos (He initialization)
- Forward pass com ReLU (ocultas) e Tanh (sa√≠da)
- M√©todos para serializar/deserializar pesos (genoma)

#### `agents/genome.py`
Fun√ß√µes auxiliares para manipula√ß√£o de genomas:
- `create_random_genome(size)`: Cria genoma aleat√≥rio
- `mutate_genome(genome, rate, std)`: Aplica muta√ß√£o gaussiana
- `crossover_uniform(parent1, parent2)`: Crossover uniforme
- `crossover_single_point(parent1, parent2)`: Crossover single-point

#### `agents/genetic_algorithm.py`
**Classe `GeneticAlgorithm`**: Implementa o algoritmo gen√©tico
- `__init__()`: Inicializa popula√ß√£o aleat√≥ria
- `get_population()`: Retorna popula√ß√£o atual
- `evolve(fitness_scores)`: Executa um ciclo evolutivo completo

#### `training/evaluation.py`
**Fun√ß√£o `evaluate_genome()`**: Avalia fitness de um genoma
- Cria ambiente e rede neural
- Executa m√∫ltiplos epis√≥dios
- Calcula fitness com heur√≠stica din√¢mica
- Retorna fitness m√©dio

#### `utils/launcher.py`
**Classe `ConfigScreen`**: Interface gr√°fica de configura√ß√£o (Tkinter)
- Campos para todos os hiperpar√¢metros
- Valida√ß√£o de entradas
- Atualiza√ß√£o autom√°tica de energia baseada no tamanho do grid
- Retorna dicion√°rio com configura√ß√µes

#### `utils/logger.py`
**Classe `TrainingLogger`**: Logger CSV simples
- `log(dict)`: Adiciona linha ao CSV
- Cabe√ßalhos autom√°ticos

#### `utils/paths.py`
Define diret√≥rios padr√£o:
- `MODELS_DIR = "models/"`
- `LOGS_DIR = "logs/"`
- `PLOTS_DIR = "plots/"`
- `SNAPSHOTS_DIR = "snapshots/"`
- `create_directories()`: Cria todos os diret√≥rios se n√£o existirem

#### `visualization/dashboard.py`
**Classe `DashboardRenderer`**: Dashboard unificado em Pygame
- **√Årea Esquerda**: Grid 3x3 mostrando 9 jogos simult√¢neos
- **√Årea Direita Superior**: Visualiza√ß√£o da rede neural (n√≥s e conex√µes)
- **√Årea Direita Inferior**: Gr√°fico de fitness em tempo real
- Janela redimension√°vel
- Atualiza√ß√£o em tempo real durante treinamento

#### `visualization/plots.py`
Fun√ß√µes para gera√ß√£o de gr√°ficos:
- `plot_training_curves(csv_path, output_path)`: Gera gr√°fico est√°tico de fitness
- `LivePlotter`: Classe para gr√°ficos interativos (n√£o usada no dashboard atual)

#### `visualization/board_snapshots.py`
**Fun√ß√£o `save_generation_snapshot()`**: Salva imagem est√°tica do tabuleiro
- Renderiza tabuleiro com cobra e ma√ß√£
- Salva em `snapshots/gen_XXXX.png`

#### `visualization/live_view.py`
**Fun√ß√£o `play_episode()`**: Visualizador simples de um epis√≥dio
- Renderiza jogo em tempo real
- Controles: ESC para sair
- Usado por `play_best.py`

---

## üìä Resultados e Logs

### Arquivos Gerados

Durante o treinamento, os seguintes arquivos s√£o criados:

1. **`models/best_gen_XXXX.npy`**: Melhor genoma de cada gera√ß√£o
2. **`models/best_overall.npy`**: Melhor genoma de todas as gera√ß√µes
3. **`logs/training_YYYYMMDD-HHMMSS.csv`**: Estat√≠sticas de treinamento
   - Colunas: `generation`, `best_fitness`, `mean_fitness`, `min_fitness`
4. **`plots/fitness_curve_YYYYMMDD-HHMMSS.png`**: Gr√°fico de evolu√ß√£o do fitness
5. **`snapshots/gen_XXXX.png`**: Imagens do tabuleiro em gera√ß√µes espec√≠ficas

### Interpretando os Resultados

- **Fitness Crescente**: Indica que os agentes est√£o melhorando
- **Fitness Estagnado**: Pode indicar converg√™ncia ou necessidade de ajustar hiperpar√¢metros
- **Dashboard**: Permite observar comportamento em tempo real e identificar padr√µes

---

## üîß Troubleshooting

### Erro: "ModuleNotFoundError"
- Certifique-se de que todas as depend√™ncias est√£o instaladas: `pip install -r requirements.txt`

### Erro: "FileNotFoundError" ao carregar modelo
- Execute `main_train.py` primeiro para gerar modelos
- Verifique se o caminho do modelo est√° correto

### Dashboard n√£o abre ou trava
- Reduza a velocidade de visualiza√ß√£o (FPS)
- Desabilite o dashboard e use apenas logs/gr√°ficos
- Verifique se o Pygame est√° instalado corretamente

### Performance lenta
- Reduza o tamanho da popula√ß√£o
- Reduza o n√∫mero de gera√ß√µes para testes
- Desabilite o dashboard ao vivo
- Reduza o n√∫mero de epis√≥dios por avalia√ß√£o

---

## üìù Notas Adicionais

- O c√≥digo foi desenvolvido para fins educacionais e demonstra√ß√£o de conceitos de IA
- A implementa√ß√£o √© intencionalmente simples e did√°tica (sem frameworks de ML)
- Para melhor performance, considere usar frameworks como PyTorch ou TensorFlow
- O sistema de heur√≠stica din√¢mica pode ser ajustado conforme necess√°rio

---

## üìÑ Licen√ßa

Este projeto √© fornecido como est√°, para fins educacionais.

---

**Desenvolvido com ‚ù§Ô∏è usando Python, NumPy e Algoritmos Gen√©ticos**
